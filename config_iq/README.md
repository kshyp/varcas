Subcommand	Function
model-info	Fetches model config from Hugging Face, computes parameter count (if missing).
workload-defaults	Returns typical input/output lengths, batch size, and SLAs for a given deployment type.
hardware-ls	Lists hardware from builtâ€‘in catalog; filterable by GPU, price, etc.
roofline-estimate	Runs derated roofline for a single (model, hardware, TP) combo; outputs TTFT, TPOT, throughput, bottleneck.
search-configs	Main recommendation engine. Enumerates all (hardware, TP) combos, checks memory fit, computes predicted latency, applies safety margin, filters by headroom, ranks by cost.

âœ… Key Features Implemented
Derating factors per GPU (A100, H100, A10G) for prefill (compute) and decode (memory).

Communication overhead as a multiplicative factor based on TP size.

Memory footprint check â€“ weights + KV cache must fit in GPU memory (90% limit).

Safety margin â€“ tightens SLA to avoid fragile configs.

Headroom capping â€“ rejects overâ€‘provisioned configs (>60% headroom).

Cost per 1M tokens â€“ rough estimate for throughputâ€‘oriented comparison.

Simple table output â€“ humanâ€‘readable ranking.

ðŸ“¦ Extending the Tool
Hardware catalog â€“ add more instance types (GCP, Azure) and update pricing via cloud APIs.

Derating factors â€“ populate from a JSON file; allow user overrides.

Parallelism search â€“ add pipeline parallelism (PP) and data parallelism (DP) for throughput workloads.

Continuous batching â€“ improve throughput model using vLLMâ€™s dynamic batching heuristics.

Modelâ€‘specific calibration â€“ store perâ€‘model utilization factors after benchmarking.
