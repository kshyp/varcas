#!/usr/bin/env python3
"""Generate final optimization summary."""

import json
from pathlib import Path

print("="*70)
print("BATCH SIZE OPTIMIZATION - FINAL SUMMARY")
print("="*70)

# Load all results
base = Path("varcas/profiles/roofline/batch_optimization")

# Normal load
with open(base / "results_b1.json") as f:
    normal_b1 = json.load(f)["metrics"]
with open(base / "results_b8.json") as f:
    normal_b8 = json.load(f)["metrics"]

# High load
with open(base / "highload_results_b1.json") as f:
    high_b1 = json.load(f)["metrics"]
with open(base / "highload_results_b8.json") as f:
    high_b8 = json.load(f)["metrics"]

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    OPTIMIZATION RESULTS SUMMARY                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Model:  TheBloke/Llama-2-7B-AWQ (4-bit)                             â•‘
â•‘  GPU:    Tesla T4                                                    â•‘
â•‘  Optimization:  max_num_seqs 1 â†’ 8                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
print("â”‚ NORMAL LOAD (chat_medium - 20 RPS)                                  â”‚")
print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
print(f"â”‚  Token Throughput:  {normal_b1['throughput_tok_s']:>6.1f} â†’ {normal_b8['throughput_tok_s']:<6.1f} tok/s  (+{((normal_b8['throughput_tok_s']/normal_b1['throughput_tok_s']-1)*100):.0f}%) â”‚")
print(f"â”‚  Request Throughput: {normal_b1['throughput_rps']:>6.2f} â†’ {normal_b8['throughput_rps']:<6.2f} req/s  (rate limited)  â”‚")
print(f"â”‚  TTFT p50:          {normal_b1['ttft_p50_ms']:>6.0f} â†’ {normal_b8['ttft_p50_ms']:<6.0f} ms      (+{((normal_b8['ttft_p50_ms']/normal_b1['ttft_p50_ms']-1)*100):.0f}%)   â”‚")
print(f"â”‚  TPOT p50:          {normal_b1['tpot_p50_ms']:>6.1f} â†’ {normal_b8['tpot_p50_ms']:<6.1f} ms      (+{((normal_b8['tpot_p50_ms']/normal_b1['tpot_p50_ms']-1)*100):.0f}%)   â”‚")
print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
print("â”‚ HIGH LOAD (chat_high - 50 RPS)                                      â”‚")
print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
print(f"â”‚  Token Throughput:  {high_b1['throughput_tok_s']:>6.1f} â†’ {high_b8['throughput_tok_s']:<6.1f} tok/s  (+{((high_b8['throughput_tok_s']/high_b1['throughput_tok_s']-1)*100):.0f}%) â”‚")
print(f"â”‚  Request Throughput: {high_b1['throughput_rps']:>6.2f} â†’ {high_b8['throughput_rps']:<6.2f} req/s  (+{((high_b8['throughput_rps']/high_b1['throughput_rps']-1)*100):.1f}%)   â”‚")
print(f"â”‚  Latency p50:       {high_b1['latency_p50_ms']:>6.0f} â†’ {high_b8['latency_p50_ms']:<6.0f} ms      (+{((high_b8['latency_p50_ms']/high_b1['latency_p50_ms']-1)*100):.0f}%)   â”‚")
print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         KEY INSIGHTS                                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                      â•‘
â•‘  âœ… TOKEN THROUGHPUT: +350-390% improvement                          â•‘
â•‘     â€¢ 22 â†’ 99 tok/s (normal load)                                    â•‘
â•‘     â€¢ 37 â†’ 179 tok/s (high load)                                     â•‘
â•‘                                                                      â•‘
â•‘  âœ… ROOFLINE POSITION: Moving toward compute bound                   â•‘
â•‘     â€¢ Batch=1: AI â‰ˆ 3 FLOP/Byte (memory-bound, 1.5% util)            â•‘
â•‘     â€¢ Batch=8: AI â‰ˆ 15-24 FLOP/Byte (better memory BW util)          â•‘
â•‘                                                                      â•‘
â•‘  âš ï¸  LATENCY TRADE-OFF: +30-70% increase                             â•‘
â•‘     â€¢ TTFT increases due to queue wait                               â•‘
â•‘     â€¢ TPOT increases due to batch processing                         â•‘
â•‘                                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

print("RECOMMENDED CONFIGURATION:")
print("-" * 70)
print("""python -m vllm.entrypoints.openai.api_server \\
  --model TheBloke/Llama-2-7B-AWQ \\
  --dtype half \\
  --max-model-len 2048 \\
  --max-num-seqs 8 \\        # â† ADD THIS LINE
  --gpu-memory-utilization 0.90 \\
  --quantization awq \\
  --enforce-eager \\
  --port 8000""")
print("-" * 70)

print("\nFILES GENERATED:")
print(f"  ðŸ“ {base}")
print("     â”œâ”€â”€ results_b1.json, results_b8.json")
print("     â”œâ”€â”€ highload_results_b1.json, highload_results_b8.json")
print("     â”œâ”€â”€ analysis_detailed.json")
print("     â””â”€â”€ BATCH_OPTIMIZATION_RESULTS.md")

print("\n" + "="*70)
